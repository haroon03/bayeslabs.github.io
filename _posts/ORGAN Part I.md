
<h2>Introduction</h2>
<b>Objective-Reinforced Generative Adversarial Network (ORGAN)</b> is a modified version of a basic Generative Adversarial Network (GAN). 
Before we dig deep into theory and implementation of ORGAN let me brief you about the basics of GAN. 
A simple GAN is composed of two neural networks,Generator and the Discriminator.

<b> Generator:</b> The main aim of the Generator<b>(G)</b> is to produce/generate fake samples which resemble the true data/distribution so closely, that the discriminator cannot differentiate between the true data and the fake ones, in other words, it tries to fool the discriminator. 

<b>Discriminator:</b> The Discriminator<b>(D)</b>, as the name suggests discriminates the input data and classifies whether it is from the true data sample/distribution or is a fake sample generated by the Generator(G). The Discriminator is initially trained on true labeled data samples.

Both of these networks work against each other trying to be better at their job by proving the other wrong. Their main objective is to 
generate data points that are similar to some data points in the training data;
Given an initial  training distribution p(data), the generator G samples x from a distribution p(synth) generated with random noise z, while a discriminator D looks at samples, either from p(syntetic) or from p(data), and tries to classify their identity (y) as either real x∈p(data) or fake x∈p(synth).

The model follows a min max game where we minimize the Generator function log(1−D(G(z)) so that we can fool the discriminator by generating the samples vesry close to the original distribution, while maximizing the discriminator function logi(D(x)) so that it can classify beteen
fake and real data pints more accurately.
For a single data point we have: min G max D [logD(x)]+z∼p(synthetic)(z)[log(1−D(G(z)))].
For the complete distributions we have: min G max D E[logD(x)] +E[log(1−D(G(z)))] where E is Expectation.

<h3>Training a GAN</h3>






Loss is calculated using Cross Entropy Loss method, gradients are updated via backpropagation. 

